Blog: https://www.inovex.de/de/blog/hide-adversarial-attacks-using-explainable-artificial-intelligence/

Using a composite loss function, create a model such that,
* when attacked, the GradCAM saliency map is not able to discriminate if an image was attacked or not (Targeted DeepFool is the attack method)

